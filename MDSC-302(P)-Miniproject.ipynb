{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77a7744",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">MDSC-302(P) Mini-Project</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19af2b",
   "metadata": {},
   "source": [
    "## Problem Statement :Sentiment analysis of Amazon kindle store reviews.\n",
    "\n",
    "- This project is to perform a supervised sentiment analysis on the review data that from Amazon kindle store. \n",
    "- The data consists of 982,619 reviews spanning May 1996 to July 2014.\n",
    "- Reviews with overall rating of 1, 2, or 3 are labelled as negative (\"neg\"/1), and reviews with overall rating of 4 or 5 are labelled as positive (\"pos\"/0).\n",
    "- Dataset is available here: http://jmcauley.ucsd.edu/data/amazon/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a15f60f",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e30a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/huser/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes, LogisticRegression, LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "import html\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d851982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Sentimental analysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fcb9a",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6be066f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('Kindle_Store_5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36e7795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+--------------------+----------+--------------+------------+------------------+--------------+\n",
      "|      asin|helpful|overall|          reviewText|reviewTime|    reviewerID|reviewerName|           summary|unixReviewTime|\n",
      "+----------+-------+-------+--------------------+----------+--------------+------------+------------------+--------------+\n",
      "|B000F83SZQ| [0, 0]|    5.0|I enjoy vintage b...|05 5, 2014|A1F6404F1VG29J|  Avidreader|Nice vintage story|    1399248000|\n",
      "|B000F83SZQ| [2, 2]|    4.0|This book is a re...|01 6, 2014| AN0N05A9LIJEQ|    critters|      Different...|    1388966400|\n",
      "|B000F83SZQ| [2, 2]|    4.0|This was a fairly...|04 4, 2014| A795DMNCJILA6|         dot|             Oldie|    1396569600|\n",
      "+----------+-------+-------+--------------------+----------+--------------+------------+------------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de710798",
   "metadata": {},
   "source": [
    "## Creating Positive(0) and Negative(1) responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd73eee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:===================================>                    (48 + 3) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|153331|\n",
      "|    0|829250|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:==================================================>     (68 + 3) / 75]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView('kindle_json_view')\n",
    "\n",
    "data_json = spark.sql('''\n",
    "  SELECT CASE WHEN overall<4 THEN 1\n",
    "          ELSE 0\n",
    "          \n",
    "          END as label,\n",
    "        reviewText as text\n",
    "  FROM kindle_json_view\n",
    "  WHERE length(reviewText)>2''')\n",
    "\n",
    "data_json.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a53bc3",
   "metadata": {},
   "source": [
    "## Sampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8191631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|    0|I am not for sure...|\n",
      "|    0|This is yet anoth...|\n",
      "|    0|I almost didn't g...|\n",
      "|    0|L'Among classic. ...|\n",
      "|    0|The reporting is ...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos = data_json.where('label=0').sample(False, 0.05, seed=1220)\n",
    "neg = data_json.where('label=1').sample(False, 0.25, seed=1220)\n",
    "data = pos.union(neg)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c104f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|38219|\n",
      "|    0|41634|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b192f0",
   "metadata": {},
   "source": [
    "## Function to pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb27761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing function\n",
    "def preprocessing(text):\n",
    "   \n",
    "    line = html.unescape(text)\n",
    "    line = line.replace(\"can't\", 'can not')\n",
    "    line = line.replace(\"n't\", \" not\")\n",
    "    \n",
    "    pad_punct = str.maketrans({key: \" {0} \".format(key) for key in string.punctuation}) \n",
    "    line = line.translate(pad_punct)\n",
    "    line = line.lower()\n",
    "    line = line.split() \n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    line = [lemmatizer.lemmatize(t) for t in line] \n",
    "    \n",
    "    # Negation handling\n",
    "    tokens = []\n",
    "    negated = False\n",
    "    for t in line:\n",
    "        if t in ['not', 'no']:\n",
    "            negated = not negated\n",
    "        elif t in string.punctuation or not t.isalpha():\n",
    "            negated = False\n",
    "        else:\n",
    "            tokens.append('not_' + t if negated else t)\n",
    "    \n",
    "    invalidChars = str(string.punctuation.replace(\"_\", \"\"))  \n",
    "    bi_tokens = list(nltk.bigrams(line))\n",
    "    bi_tokens = list(map('_'.join, bi_tokens))\n",
    "    bi_tokens = [i for i in bi_tokens if all(j not in invalidChars for j in i)]\n",
    "    tri_tokens = list(nltk.trigrams(line))\n",
    "    tri_tokens = list(map('_'.join, tri_tokens))\n",
    "    tri_tokens = [i for i in tri_tokens if all(j not in invalidChars for j in i)]\n",
    "    tokens = tokens + bi_tokens + tri_tokens      \n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "957e82b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'think', 'this', 'book', 'is', 'not_good', 'it', 'is', 'full', 'of', 'typo', 'and', 'factual', 'error', 'that', 'i', 'can', 'not_ignore', 'i_think', 'think_this', 'this_book', 'book_is', 'is_not', 'not_good', 'it_is', 'is_full', 'full_of', 'of_typo', 'typo_and', 'and_factual', 'factual_error', 'error_that', 'that_i', 'i_can', 'can_not', 'not_ignore', 'i_think_this', 'think_this_book', 'this_book_is', 'book_is_not', 'is_not_good', 'it_is_full', 'is_full_of', 'full_of_typo', 'of_typo_and', 'typo_and_factual', 'and_factual_error', 'factual_error_that', 'error_that_i', 'that_i_can', 'i_can_not', 'can_not_ignore']\n"
     ]
    }
   ],
   "source": [
    "review = preprocessing(\"I think this book is not good. It is full of typos and factual errors that I can't ignore.\")\n",
    "print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44200ddf",
   "metadata": {},
   "source": [
    "## Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3106eae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|                text|              tokens|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|I am not for sure...|[i, am, not_for, ...|\n",
      "|    0|This is yet anoth...|[this, is, yet, a...|\n",
      "|    0|I almost didn't g...|[i, almost, did, ...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preprocessing_udf = F.udf(preprocessing, ArrayType(StringType()))\n",
    "data_tokens = data.withColumn('tokens', preprocessing_udf(F.col('text')))\n",
    "data_tokens.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572545fb",
   "metadata": {},
   "source": [
    "## Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4badd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|26712|\n",
      "|    0|29077|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split data to 70% for training and 30% for testing\n",
    "df_train, df_test = data_tokens.randomSplit([0.7,0.3],seed=18)\n",
    "df_train.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "413211eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: int, text: string, tokens: array<string>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb0327d",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c2cbd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 11:53:03 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 11:53:07 WARN MemoryStore: Not enough space to cache rdd_82_4 in memory! (computed 31.5 MiB so far)\n",
      "21/12/01 11:53:15 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 11:53:16 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 11:53:20 WARN MemoryStore: Not enough space to cache rdd_82_4 in memory! (computed 31.5 MiB so far)\n",
      "21/12/01 11:53:29 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 11:53:45 WARN DAGScheduler: Broadcasting large task binary with size 10.7 MiB\n",
      "[Stage 42:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|                text|              tokens|               c_vec|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0|\"A Light in the D...|[a, light, in, th...|(238355,[0,1,2,3,...|(238355,[0,1,2,3,...|[-14874.650633549...|[1.0,1.3995489911...|       0.0|\n",
      "|    0|\"Lokant\" by Charl...|[lokant, by, char...|(238355,[0,1,2,3,...|(238355,[0,1,2,3,...|[-9401.2509876576...|[1.0,2.7927877286...|       0.0|\n",
      "|    0|\"Max\" was written...|[max, wa, written...|(238355,[0,1,2,3,...|(238355,[0,1,2,3,...|[-42400.459294817...|[1.75287468380991...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "c_vec = CountVectorizer(inputCol='tokens', outputCol='c_vec', minDF=5.0)\n",
    "idf = IDF(inputCol=\"c_vec\", outputCol=\"features\")\n",
    "nb = NaiveBayes()\n",
    "\n",
    "nb_pipeline = Pipeline(stages=[c_vec, idf, nb])\n",
    "\n",
    "nb_model = nb_pipeline.fit(df_train)\n",
    "nb_test_pred = nb_model.transform(df_test)\n",
    "nb_test_pred.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4722633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 11:53:54 WARN DAGScheduler: Broadcasting large task binary with size 10.7 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC of the Naive Bayes model: 0.8599035690204784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 11:54:57 WARN DAGScheduler: Broadcasting large task binary with size 10.7 MiB\n",
      "[Stage 54:============================================>           (11 + 3) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes model: 0.8600814494680851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 54:====================================================>   (13 + 1) / 14]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nb_ROC_ = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')\n",
    "nb_ROC = nb_ROC_.evaluate(nb_test_pred)\n",
    "print(\"ROC of the Naive Bayes model: {}\".format(nb_ROC))\n",
    "\n",
    "nb_Acc_ = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "nb_Acc = nb_Acc_.evaluate(nb_test_pred)\n",
    "print(\"Accuracy of the Naive Bayes model: {}\".format(nb_Acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e57aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 11:56:19 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 11:56:27 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 11:56:29 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 11:56:39 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 11:57:04 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "21/12/01 11:57:34 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 11:57:43 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 11:57:44 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 11:57:54 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 11:58:17 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "21/12/01 11:58:43 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 11:58:51 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 11:58:53 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 11:59:03 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 11:59:25 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "21/12/01 11:59:51 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 11:59:58 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 11:59:59 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/12/01 12:00:07 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/12/01 12:00:17 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/12/01 12:00:42 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:00:48 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:00:49 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/12/01 12:00:58 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/12/01 12:01:08 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/12/01 12:01:33 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:01:40 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:01:41 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/12/01 12:01:49 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/12/01 12:02:00 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/12/01 12:02:23 WARN DAGScheduler: Broadcasting large task binary with size 1862.3 KiB\n",
      "21/12/01 12:02:29 WARN DAGScheduler: Broadcasting large task binary with size 1863.3 KiB\n",
      "21/12/01 12:02:29 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:02:37 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:02:43 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/01 12:03:06 WARN DAGScheduler: Broadcasting large task binary with size 1862.3 KiB\n",
      "21/12/01 12:03:12 WARN DAGScheduler: Broadcasting large task binary with size 1863.3 KiB\n",
      "21/12/01 12:03:13 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:03:19 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:03:26 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/01 12:03:46 WARN DAGScheduler: Broadcasting large task binary with size 1862.3 KiB\n",
      "21/12/01 12:03:52 WARN DAGScheduler: Broadcasting large task binary with size 1863.3 KiB\n",
      "21/12/01 12:03:53 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:04:00 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:04:06 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/01 12:04:27 WARN DAGScheduler: Broadcasting large task binary with size 1292.9 KiB\n",
      "21/12/01 12:04:33 WARN DAGScheduler: Broadcasting large task binary with size 1293.9 KiB\n",
      "21/12/01 12:04:33 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:04:39 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:04:44 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/12/01 12:05:05 WARN DAGScheduler: Broadcasting large task binary with size 1292.9 KiB\n",
      "21/12/01 12:05:11 WARN DAGScheduler: Broadcasting large task binary with size 1293.9 KiB\n",
      "21/12/01 12:05:11 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:05:17 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:05:22 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/12/01 12:05:42 WARN DAGScheduler: Broadcasting large task binary with size 1292.9 KiB\n",
      "21/12/01 12:05:48 WARN DAGScheduler: Broadcasting large task binary with size 1293.9 KiB\n",
      "21/12/01 12:05:48 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:05:54 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:05:59 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/12/01 12:06:25 WARN DAGScheduler: Broadcasting large task binary with size 1824.0 KiB\n",
      "21/12/01 12:06:31 WARN DAGScheduler: Broadcasting large task binary with size 1821.5 KiB\n",
      "21/12/01 12:06:35 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:07:01 WARN DAGScheduler: Broadcasting large task binary with size 1824.0 KiB\n",
      "21/12/01 12:07:06 WARN DAGScheduler: Broadcasting large task binary with size 1821.5 KiB\n",
      "21/12/01 12:07:10 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:07:45 WARN DAGScheduler: Broadcasting large task binary with size 1824.0 KiB\n",
      "21/12/01 12:07:53 WARN DAGScheduler: Broadcasting large task binary with size 1821.5 KiB\n",
      "21/12/01 12:07:57 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:08:28 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:08:40 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:08:41 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:08:56 WARN DAGScheduler: Broadcasting large task binary with size 7.7 MiB\n",
      "21/12/01 12:09:27 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "21/12/01 12:10:05 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:10:15 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:10:16 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:10:27 WARN DAGScheduler: Broadcasting large task binary with size 7.7 MiB\n",
      "21/12/01 12:11:01 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "21/12/01 12:11:33 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:11:44 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:11:45 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:11:57 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:12:29 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "21/12/01 12:12:59 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:13:08 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:13:09 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "21/12/01 12:13:18 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "21/12/01 12:13:30 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/12/01 12:13:58 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:14:07 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:14:08 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "21/12/01 12:14:17 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "21/12/01 12:14:28 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 12:14:56 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:15:05 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:15:06 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "21/12/01 12:15:16 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "21/12/01 12:15:28 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/12/01 12:15:57 WARN DAGScheduler: Broadcasting large task binary with size 1868.6 KiB\n",
      "21/12/01 12:16:04 WARN DAGScheduler: Broadcasting large task binary with size 1869.7 KiB\n",
      "21/12/01 12:16:04 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:16:13 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:16:20 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/01 12:16:46 WARN DAGScheduler: Broadcasting large task binary with size 1868.6 KiB\n",
      "21/12/01 12:16:52 WARN DAGScheduler: Broadcasting large task binary with size 1869.7 KiB\n",
      "21/12/01 12:16:53 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:17:01 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:17:08 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/01 12:17:36 WARN DAGScheduler: Broadcasting large task binary with size 1868.6 KiB\n",
      "21/12/01 12:17:42 WARN DAGScheduler: Broadcasting large task binary with size 1869.7 KiB\n",
      "21/12/01 12:17:43 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:17:51 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:17:57 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/01 12:18:23 WARN DAGScheduler: Broadcasting large task binary with size 1298.8 KiB\n",
      "21/12/01 12:18:29 WARN DAGScheduler: Broadcasting large task binary with size 1299.8 KiB\n",
      "21/12/01 12:18:29 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:18:36 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:18:41 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/12/01 12:19:05 WARN DAGScheduler: Broadcasting large task binary with size 1298.8 KiB\n",
      "21/12/01 12:19:11 WARN DAGScheduler: Broadcasting large task binary with size 1299.8 KiB\n",
      "21/12/01 12:19:12 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:19:19 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:19:23 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/12/01 12:19:49 WARN DAGScheduler: Broadcasting large task binary with size 1298.8 KiB\n",
      "21/12/01 12:19:55 WARN DAGScheduler: Broadcasting large task binary with size 1299.8 KiB\n",
      "21/12/01 12:19:56 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:20:03 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:20:08 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/12/01 12:20:39 WARN DAGScheduler: Broadcasting large task binary with size 1835.5 KiB\n",
      "21/12/01 12:20:44 WARN DAGScheduler: Broadcasting large task binary with size 1833.0 KiB\n",
      "21/12/01 12:20:48 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:21:18 WARN DAGScheduler: Broadcasting large task binary with size 1835.5 KiB\n",
      "21/12/01 12:21:25 WARN DAGScheduler: Broadcasting large task binary with size 1833.0 KiB\n",
      "21/12/01 12:21:28 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:21:58 WARN DAGScheduler: Broadcasting large task binary with size 1835.5 KiB\n",
      "21/12/01 12:22:04 WARN DAGScheduler: Broadcasting large task binary with size 1833.0 KiB\n",
      "21/12/01 12:22:07 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:22:37 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:22:48 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:22:49 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:23:02 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:23:42 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "21/12/01 12:24:18 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:24:29 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:24:30 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:24:42 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:25:25 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "21/12/01 12:25:57 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:26:07 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:26:09 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:26:22 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:26:57 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "21/12/01 12:27:28 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:27:36 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:27:37 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/12/01 12:27:47 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/12/01 12:28:01 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/12/01 12:28:31 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:28:39 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:28:40 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/12/01 12:28:50 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/12/01 12:29:01 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/12/01 12:29:30 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:29:39 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:29:40 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/12/01 12:29:50 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "21/12/01 12:30:01 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/12/01 12:30:29 WARN DAGScheduler: Broadcasting large task binary with size 1860.1 KiB\n",
      "21/12/01 12:30:38 WARN DAGScheduler: Broadcasting large task binary with size 1861.2 KiB\n",
      "21/12/01 12:30:38 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:30:47 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:30:54 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/01 12:31:22 WARN DAGScheduler: Broadcasting large task binary with size 1860.1 KiB\n",
      "21/12/01 12:31:30 WARN DAGScheduler: Broadcasting large task binary with size 1861.2 KiB\n",
      "21/12/01 12:31:31 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:31:39 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:31:46 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/01 12:32:15 WARN DAGScheduler: Broadcasting large task binary with size 1860.1 KiB\n",
      "21/12/01 12:32:22 WARN DAGScheduler: Broadcasting large task binary with size 1861.2 KiB\n",
      "21/12/01 12:32:22 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:32:31 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:32:38 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/01 12:33:05 WARN DAGScheduler: Broadcasting large task binary with size 1292.4 KiB\n",
      "21/12/01 12:33:11 WARN DAGScheduler: Broadcasting large task binary with size 1293.4 KiB\n",
      "21/12/01 12:33:11 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:33:19 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:33:24 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 12:33:49 WARN DAGScheduler: Broadcasting large task binary with size 1292.4 KiB\n",
      "21/12/01 12:33:55 WARN DAGScheduler: Broadcasting large task binary with size 1293.4 KiB\n",
      "21/12/01 12:33:56 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:34:03 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:34:08 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/12/01 12:34:34 WARN DAGScheduler: Broadcasting large task binary with size 1292.4 KiB\n",
      "21/12/01 12:34:41 WARN DAGScheduler: Broadcasting large task binary with size 1293.4 KiB\n",
      "21/12/01 12:34:41 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:34:48 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:34:53 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/12/01 12:35:26 WARN DAGScheduler: Broadcasting large task binary with size 1822.4 KiB\n",
      "21/12/01 12:35:32 WARN DAGScheduler: Broadcasting large task binary with size 1819.9 KiB\n",
      "21/12/01 12:35:35 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:36:06 WARN DAGScheduler: Broadcasting large task binary with size 1822.4 KiB\n",
      "21/12/01 12:36:13 WARN DAGScheduler: Broadcasting large task binary with size 1819.9 KiB\n",
      "21/12/01 12:36:16 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:36:46 WARN DAGScheduler: Broadcasting large task binary with size 1822.4 KiB\n",
      "21/12/01 12:36:53 WARN DAGScheduler: Broadcasting large task binary with size 1819.9 KiB\n",
      "21/12/01 12:36:56 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:37:28 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:37:40 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:37:41 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:37:53 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:38:25 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "21/12/01 12:39:01 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:39:12 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:39:13 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:39:26 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:40:04 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "21/12/01 12:40:37 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:40:47 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "21/12/01 12:40:48 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:41:01 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "21/12/01 12:41:44 WARN DAGScheduler: Broadcasting large task binary with size 11.8 MiB\n",
      "21/12/01 12:42:28 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:42:36 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:42:37 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "21/12/01 12:42:47 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "21/12/01 12:42:57 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/12/01 12:43:28 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:43:38 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:43:39 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "21/12/01 12:43:49 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "21/12/01 12:44:00 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/12/01 12:44:30 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:44:39 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "21/12/01 12:44:40 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "21/12/01 12:44:50 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "21/12/01 12:45:01 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "21/12/01 12:45:30 WARN DAGScheduler: Broadcasting large task binary with size 1866.4 KiB\n",
      "21/12/01 12:45:37 WARN DAGScheduler: Broadcasting large task binary with size 1867.4 KiB\n",
      "21/12/01 12:45:38 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:45:46 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:45:52 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/01 12:46:23 WARN DAGScheduler: Broadcasting large task binary with size 1866.4 KiB\n",
      "21/12/01 12:46:31 WARN DAGScheduler: Broadcasting large task binary with size 1867.4 KiB\n",
      "21/12/01 12:46:32 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:46:40 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:46:46 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/01 12:47:13 WARN DAGScheduler: Broadcasting large task binary with size 1866.4 KiB\n",
      "21/12/01 12:47:20 WARN DAGScheduler: Broadcasting large task binary with size 1867.4 KiB\n",
      "21/12/01 12:47:21 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:47:29 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "21/12/01 12:47:36 WARN DAGScheduler: Broadcasting large task binary with size 5.8 MiB\n",
      "21/12/01 12:48:02 WARN DAGScheduler: Broadcasting large task binary with size 1299.9 KiB\n",
      "21/12/01 12:48:09 WARN DAGScheduler: Broadcasting large task binary with size 1300.9 KiB\n",
      "21/12/01 12:48:09 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:48:16 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:48:20 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/12/01 12:48:46 WARN DAGScheduler: Broadcasting large task binary with size 1299.9 KiB\n",
      "21/12/01 12:48:52 WARN DAGScheduler: Broadcasting large task binary with size 1300.9 KiB\n",
      "21/12/01 12:48:53 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:49:00 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:49:05 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/12/01 12:49:32 WARN DAGScheduler: Broadcasting large task binary with size 1299.9 KiB\n",
      "21/12/01 12:49:38 WARN DAGScheduler: Broadcasting large task binary with size 1300.9 KiB\n",
      "21/12/01 12:49:39 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:49:45 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:49:50 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "21/12/01 12:50:20 WARN DAGScheduler: Broadcasting large task binary with size 1833.7 KiB\n",
      "21/12/01 12:50:26 WARN DAGScheduler: Broadcasting large task binary with size 1831.2 KiB\n",
      "21/12/01 12:50:30 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:51:01 WARN DAGScheduler: Broadcasting large task binary with size 1833.7 KiB\n",
      "21/12/01 12:51:07 WARN DAGScheduler: Broadcasting large task binary with size 1831.2 KiB\n",
      "21/12/01 12:51:10 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:51:42 WARN DAGScheduler: Broadcasting large task binary with size 1833.7 KiB\n",
      "21/12/01 12:51:48 WARN DAGScheduler: Broadcasting large task binary with size 1831.2 KiB\n",
      "21/12/01 12:51:52 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "21/12/01 12:52:27 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "21/12/01 12:52:38 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "21/12/01 12:52:39 WARN DAGScheduler: Broadcasting large task binary with size 4.9 MiB\n",
      "21/12/01 12:52:39 WARN MemoryStore: Not enough space to cache rdd_82_1 in memory! (computed 28.2 MiB so far)\n",
      "21/12/01 12:52:51 WARN DAGScheduler: Broadcasting large task binary with size 4.9 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nb_paramGrid = (ParamGridBuilder()\n",
    "                .addGrid(c_vec.minDF, [3.0, 5.0, 7.0, 10.0, 15.0])\n",
    "                .addGrid(nb.smoothing, [0.1, 0.5, 1.0])\n",
    "                .build())\n",
    "nb_cv = CrossValidator(estimator= nb_pipeline, estimatorParamMaps= nb_paramGrid, evaluator= nb_Acc_, numFolds= 4)\n",
    "nb_cv_model = nb_cv.fit(df_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecac06e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 13:22:47 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "[Stage 664:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes cross validation model: 0.8609541223404256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nb_cv_test = nb_cv_model.transform(df_test)\n",
    "nb_cv_Acc = nb_Acc_.evaluate(nb_cv_test)\n",
    "print(\"Accuracy of the Naive Bayes cross validation model: {}\".format(nb_cv_Acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195847df",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60684427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 13:27:02 WARN MemoryStore: Not enough space to cache rdd_82_9 in memory! (computed 30.4 MiB so far)\n",
      "21/12/01 13:27:22 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 13:27:35 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 13:27:36 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:27:37 WARN MemoryStore: Not enough space to cache rdd_82_0 in memory! (computed 27.6 MiB so far)\n",
      "21/12/01 13:28:00 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:28:01 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:28:02 WARN MemoryStore: Not enough space to cache rdd_82_0 in memory! (computed 27.6 MiB so far)\n",
      "21/12/01 13:28:37 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:28:38 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:28:41 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:28:42 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:28:47 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:28:48 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:28:54 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:28:56 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:29:03 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:29:04 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:29:11 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:29:13 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:29:19 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=5)\n",
    "lr_pipeline = Pipeline(stages=[c_vec, idf, lr])\n",
    "\n",
    "lr_model = lr_pipeline.fit(df_train)\n",
    "lr_test = lr_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc9bfd83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 13:29:22 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC of the Logistic model: 0.8665037805637058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 13:30:44 WARN DAGScheduler: Broadcasting large task binary with size 8.9 MiB\n",
      "[Stage 721:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic model: 0.8676446143617021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_ROC_ = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')\n",
    "lr_ROC = lr_ROC_.evaluate(lr_test)\n",
    "print(\"ROC of the Logistic model: {}\".format(lr_ROC))\n",
    "\n",
    "lr_Acc_ = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "lr_Acc = lr_Acc_.evaluate(lr_test)\n",
    "print(\"Accuracy of the Logistic model: {}\".format(lr_Acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9b726",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbcd72e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 13:32:55 WARN MemoryStore: Not enough space to cache rdd_82_9 in memory! (computed 30.4 MiB so far)\n",
      "21/12/01 13:33:20 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 13:33:40 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 13:33:41 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:33:41 WARN MemoryStore: Not enough space to cache rdd_82_0 in memory! (computed 27.6 MiB so far)\n",
      "21/12/01 13:34:11 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:34:12 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:34:13 WARN MemoryStore: Not enough space to cache rdd_82_0 in memory! (computed 27.6 MiB so far)\n",
      "21/12/01 13:35:34 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:35:36 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:35:41 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:35:42 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:35:45 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:35:47 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:35:49 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:35:50 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:35:55 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:35:55 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:35:59 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:36:00 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:36:01 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:36:02 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:36:05 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:36:06 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "21/12/01 13:36:09 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(maxIter=4)\n",
    "lsvc_pipeline = Pipeline(stages=[c_vec, idf, lsvc])\n",
    "\n",
    "lsvc_model = lsvc_pipeline.fit(df_train)\n",
    "lsvc_test = lsvc_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c54c5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 13:38:07 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC of the svc model: 0.8656701853902683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 13:39:13 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n",
      "[Stage 760:===================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the svc model: 0.8670628324468085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lsvc_ROC_ = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label')\n",
    "lsvc_ROC = lsvc_ROC_.evaluate(lsvc_test)\n",
    "print(\"ROC of the svc model: {}\".format(lsvc_ROC))\n",
    "\n",
    "lsvc_Acc_ = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "lsvc_Acc = lsvc_Acc_.evaluate(lsvc_test)\n",
    "print(\"Accuracy of the svc model: {}\".format(lsvc_Acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f943fc9",
   "metadata": {},
   "source": [
    "## Predicting new reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7929055",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_1 = [\"I loved this book. The author made me think long and hard about our split government and the trials of these three young women in Paris during the early 1940s when they fell under Nazi rule. I know much of this history but she brought it to life and placed me on the scene. Friends of family who underwent a camp don't talk about it much but to read this, though I've seen films regarding it, she really brought it to life in a way that you can't ignore what was happening.\"]\n",
    "review_2 = [\"I am never buying books from Amazon Kindle again. They NEVER arrive anymore on either of the devices where I used to read them. I have been on the phone for at least two working business days with Amazon reps. Some don't speak good English - poor souls, I know they're desperate for jobs and they're all in India or someplace, not their fault they have to work for this horrible corporation.\"]\n",
    "review_3 = [\"I enjoyed reading a Perfect New World: A Novel Kindle Edition by Dr. Jacob Lavi. It was an ingenious and creative look at a possible future for man and the earth. Dr. Lavi described a future world that seemed possible. He highlighted the way we are degrading our planet by our excesses.\"]\n",
    "review_4 = [\"The book has too much detail about the history of the US prison system and is very repetitive about his conversations with other guards. Prisons are terrible places but highlighting one Louisiana prison doesn't seem right. Does he ever consider why these people are there or what they did to their victims ?Did they all have poor lawyers or were they all victims of racism or were they repeat offenders ?Some of their crimes mentioned deserve harsher punishment than they received. Skipped many pages which were just a bore.\"]\n",
    "review_5 = [\"She just passed away but this is the only magazine that she loved out of the 8 I ordered. I was quite amazed since she was a conservative Hindu lady. Then my wife also loved this one.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f39d33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"text\", StringType(), True)])\n",
    "\n",
    "text = [review_1, review_2, review_3, review_4, review_5]\n",
    "reviews = spark.createDataFrame(text, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe374b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 763:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|              tokens|\n",
      "+--------------------+--------------------+\n",
      "|I loved this book...|[i, loved, this, ...|\n",
      "|I am never buying...|[i, am, never, bu...|\n",
      "|I enjoyed reading...|[i, enjoyed, read...|\n",
      "|The book has too ...|[the, book, ha, t...|\n",
      "|She just passed a...|[she, just, passe...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 763:============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "reviews_token = reviews.withColumn('tokens', preprocessing_udf(F.col('text')))\n",
    "reviews_token.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff04ddf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 13:42:26 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "21/12/01 13:42:27 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "[Stage 765:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                text|prediction|\n",
      "+--------------------+----------+\n",
      "|I loved this book...|       0.0|\n",
      "|I am never buying...|       1.0|\n",
      "|I enjoyed reading...|       0.0|\n",
      "|The book has too ...|       1.0|\n",
      "|She just passed a...|       0.0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = nb_cv_model.transform(reviews_token)\n",
    "result.select('text', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbaff91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
